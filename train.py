# -*- coding: utf-8 -*-
"""CW1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HEh8zYk4A-KDzNFaAuqWNbBFgxlNiuoz
"""

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)
import sys
sys.path.append('/content/gdrive/MyDrive/Colab Notebooks')

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import matplotlib.pyplot as plt # matplotlib is a library which is used for graphs and plots in this coursework.
#import my_utils as mu
import torch # PyTorch library is used for creating deep learning model
import random # used for random elements
import torch.nn as nn # nn contains functions that can be used for deep learning model
import numpy as np # contains mathematical and logical elements that can be used for the project
import torchvision # used for getting pretrained models
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
# defining trainset and dataset
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
# loading the trainloader for training part of the model and testloader for testing part of the model.
trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)
testloader = DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)



import torch
import torch.nn as nn

class Model(torch.nn.Module):
    def __init__(self, num_inputs, num_outputs, N, K):
        super(Model, self).__init__()
 # model backbone consists of blocks
        class Block(nn.Module):
            def __init__(self, num_inputs, num_outputs, K):
                super(Block, self).__init__()
                # Using function called AdaptiveAvgPool2d to obtain the spatial average pool for the project
                self.spatialAveragePool = nn.AdaptiveAvgPool2d((1,1))
                self.linear1 = nn.Linear(num_inputs, K)
                self.convs = nn.ModuleList()
                self.bns = nn.ModuleList()
                for i in range(K):
                    self.convs.append(nn.Conv2d(num_inputs, num_outputs, kernel_size=3, padding=1))
                    self.bns.append(nn.BatchNorm2d(num_outputs))
                self.rl1 = nn.ReLU()

            def block_forward(self, x):
                spatial_average = self.spatialAveragePool(x)
                spatial_average_flat = spatial_average.view(x.size(0), -1)
                #using the function g to create a vector called a
                a = self.linear1(spatial_average_flat)
                a = self.rl1(a)
                out = 0
                for i in range(len(self.convs)):
                    conv_out = self.convs[i](x)
                    bn_out = self.bns[i](conv_out)
                    out += a[:, i].view(-1, 1, 1, 1) * bn_out
                out = self.rl1(out)
                return out

        self.blocks = nn.ModuleList()
        for i in range(N):
            num_inputs = num_inputs if i == 0 else num_outputs
            self.blocks.append(Block(num_inputs, num_outputs, K))
        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(num_outputs, 10)

    def forward(self, x):
        out = x
        for idx, block in enumerate(self.blocks):
            out = block.block_forward(out)

            if idx == len(self.blocks) - 1:
                height, width = out.size(2), out.size(3)
                avg_pool = nn.AvgPool2d(kernel_size=(height, width))
                f = avg_pool(out)
                break

        f = f.view(f.size(0), -1)
        f = self.fc(f)
        return f
# Using GPU for training the code, if it's not available use CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# Creating an instance of the model
model = Model(num_inputs=3, num_outputs=32, N=8, K=5)

import torch.optim as optim



model.to(device)  # Sending the model to GPU if available

# Starting the loss and optimizer functions
loss_function = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)

# Training loop
num_epochs = 25
losses = []
accuracies = []
accuracies_test = []

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    total = 0
    correct = 0
    for i, data in enumerate(trainloader, 0):
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

        # Zero the parameter gradients
        optimizer.zero_grad()

        # Forward pass
        outputs = model(inputs)

        # Compute the loss and backpropagate
        loss = loss_function(outputs, labels)
        loss.backward()

        # Update the model parameters
        optimizer.step()

        running_loss += loss.item()
        # Calculate accuracy
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    model.eval()
    correct_test = 0
    total_test = 0
    with torch.no_grad():
        for data in testloader:
            inputs, labels = data
            inputs, labels = inputs.to(device), labels.to(device)

            outputs = model(inputs)

            # Calculate accuracy
            _, predicted = torch.max(outputs.data, 1)
            total_test += labels.size(0)
            correct_test += (predicted == labels).sum().item()


    test_accuracy = 100 * correct_test / total_test

    print(f"Epoch {epoch + 1}, Loss: {running_loss / (i + 1)}, Training Accuracy: {100 * correct / total}%, Test Accuracy: {test_accuracy}%")
    accuracy = correct/total*100
    losses.append(running_loss)
    accuracies.append(accuracy)
    accuracies_test.append(test_accuracy)

plt.figure()
plt.plot(range(1, num_epochs+1), losses)
plt.title('Training evolution of loss')
plt.xlabel('Epoch')
plt.ylabel('Training loss')

plt.figure()
plt.plot(range(1, num_epochs+1), accuracies)
plt.title('Training evolution of accuracy for training set')
plt.xlabel('Epoch')
plt.ylabel('Training accuracy')

plt.figure()
plt.plot(range(1, num_epochs+1), accuracies_test)
plt.title('Training evolution of accuracy for testing set')
plt.xlabel('Epoch')
plt.ylabel('Training accuracy')



